{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import requests\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "#import api_key\n",
    "\n",
    "possibleSubjectAreas = ['AGRI','ARTS','BIOC','BUSI','CENG','CHEM','COMP','DECI','DENT',\n",
    "                'EART','ECON','ENER','ENGI','ENVI','HEAL','IMMU','MATE','MATH','MEDI','NEUR',\n",
    "                'NURS','PHAR','PHYS','PSYC','SOCI','VETE','MULT']\n",
    "\n",
    "years = range(2018,1990,-1)\n",
    "\n",
    "\n",
    "SCOPUS_PAGE_SIZE=25\n",
    "SCOPUS_MAX_RESULTS_PER_QUERY=5000\n",
    "\n",
    "api_token = 'your_api_token'\n",
    "my_api_key = '0b1939facfd1a6d769ef6f31a9b9d92f'#api_key.my_api_key #mine\n",
    "#default_api_key = '7f59af901d2d86f78a1fd60c1bf9426a' #default\n",
    "\n",
    "\n",
    "api_url_base = 'https://api.elsevier.com/content/search/scopus'\n",
    "headers = {'Accept' : 'application/json',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions get a set of authors ID randomly. It then samples papers that are from authors ID in the set. \n",
    "\n",
    "getMask gets a random 11 digits integer (scopus author IDs are 11 digits). then we mask some digits with '?' (meaning it's ok whatever their value is). If we mask one digit, it means we fix 10 out of 11 digits (we identify 10 authors). for each more digits we mask, it is a 10x increase. for n masked digits (n is the \"masklevel\"), we restrict the query to 10^n authors. \n",
    "\n",
    "or a given year, subjectArea, authorIDMask (that is, set of authorIDs),  getScopusProcsData then returns papers from authors in that set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMask(maskLevel):\n",
    "    assert (maskLevel<=10) and (maskLevel>0)\n",
    "    authorIDMask = list(str(random.randint(1, 99999999999)))\n",
    "    #pad with leading zeros if smaller than 11 digits\n",
    "    pad = 11 - len(authorIDMask)\n",
    "    pad_array = ['0']*pad\n",
    "    pad_array.extend(authorIDMask)\n",
    "    authorIDMask = pad_array\n",
    "    #always mask the first (it's newer and it can bias towards new authors)\n",
    "    authorIDMask[0]='?'\n",
    "    mask = random.sample(range(1, 11), maskLevel-1)\n",
    "    #mask.append(0)\n",
    "    for i in mask:\n",
    "        authorIDMask[i]='?'\n",
    "    completed_authorIDMask=\"\".join(authorIDMask)\n",
    "    return completed_authorIDMask\n",
    "\n",
    "#create a fixed mask for titles, consisting of N characters with M ? chars in between\n",
    "def get_title_mask(num_random_chars, in_between_chars):\n",
    "    \n",
    "    s = '*'\n",
    "    for i in range(num_random_chars):\n",
    "        s += '?' * in_between_chars\n",
    "        c = random.choice(string.ascii_lowercase)\n",
    "        s+=c\n",
    "    s += '*'\n",
    "    return s\n",
    "\n",
    "#retrieve up to retrieveCount papers for a given year, subjectArea, authorIDMask\n",
    "# def getScopusProcsData_per_mask(year, subjectArea, maskLevel, retrieveCountForEachMask, api_key):\n",
    "    \n",
    "#     results = []\n",
    "#     noMoreResults = False\n",
    "#     start=0\n",
    "\n",
    "#     while (len(results) < retrieveCountForEachMask ) and not noMoreResults:\n",
    "#         authorIDMask = getMask(maskLevel)\n",
    "#         query_count = SCOPUS_PAGE_SIZE\n",
    "#         query = 'query=title-abs-key(a*)%20AND%20AU-ID(' + authorIDMask + ')%20AND%20(srctype(p)%20OR%20srctype(k))%20AND%20(doctype(cp))'\n",
    "        \n",
    "#         filter = '&date=' + str(year) + '&subj=' + subjectArea + '&count=' + str(query_count)+ '&start=' + str(start)\n",
    "#         api_url = api_url_base + '?' + query + filter + '&apiKey=' + api_key + '&httpAccept=application%2Fjson'\n",
    "#         print(api_url)\n",
    "#         response = requests.get(api_url, headers=headers)\n",
    "#         jresponse=[]\n",
    "        \n",
    "#         if response.status_code == 200:\n",
    "#             print('start:' + str(start))\n",
    "#             r = json.loads(response.content.decode('utf-8'))['search-results']\n",
    "#             if 'entry' in r:\n",
    "#                 jresponse = r['entry']\n",
    "#                 if ('error' not in jresponse[0]):\n",
    "#                     results.extend( jresponse)\n",
    "#                     print( 'in getScopusProcsData: retrieved ',len(results),'out of ',retrieveCountForEachMask, s )\n",
    "#         else: \n",
    "#             print('\\n \\n ******', response.status_code, response.headers, response.text)\n",
    "            \n",
    "#         if (len(jresponse)<query_count):\n",
    "#             break\n",
    "#         else:\n",
    "#             start+=query_count\n",
    "\n",
    "#     return results[:retrieveCountForEachMask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This functions gets proceedings papers by first starting with a narrow authors mask (10^4 authors) and then increasing the mask if there are not enough papers to fill the requested retrieveCount.\n",
    "\n",
    "Notice that for EACH scopus query we get a different author mask, to maximise randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def getDOIsRandomly(year,subjectArea, maskLevel=4, \n",
    "#                     retrieveCount=1000,  sleepInterval=10, api_key='None'):\n",
    "        \n",
    "        \n",
    "#     retrieveCountForEachMask=retrieveCount\n",
    "#     results = []\n",
    "    \n",
    "    \n",
    "#     while (len(results)<retrieveCount) and (maskLevel<=10):\n",
    "#         start=0\n",
    "#         results_to_be_retrieved = min(retrieveCountForEachMask, retrieveCount - len(results))\n",
    "#         if (results_to_be_retrieved <=0): \n",
    "#             break\n",
    "                    \n",
    "#         callResults =  getScopusProcsData_per_mask(year, subjectArea, maskLevel, results_to_be_retrieved, api_key)\n",
    "#         results.extend(callResults)\n",
    "\n",
    "#         if (len(callResults) < results_to_be_retrieved):\n",
    "#             maskLevel += 1\n",
    "#             print ('increasing mask level to: ', maskLevel,'after results so far:',len(results),s)\n",
    "#         else:\n",
    "#             start+=SCOPUS_PAGE_SIZE\n",
    "\n",
    "#     return results\n",
    "\n",
    "\n",
    "\n",
    "# def getDOIsRandomly_noyearsubj(maskLevel=4, maxMaskLevel=7, retrieveCount=1000,   api_key='None'):\n",
    "        \n",
    "#     retrieveCountForEachMask=retrieveCount\n",
    "#     results = []\n",
    "#     attempts_with_this_mask_level=0\n",
    "#     MAX_ATTEMPTS_AT_MASK = 10\n",
    "    \n",
    "#     while (len(results)<retrieveCount) and (maskLevel<=maxMaskLevel):\n",
    "#         print('(start) maskLevel now at ', maskLevel)\n",
    "#         authorIDMask = getMask(maskLevel)\n",
    "#         titleMask = '*a*'\n",
    "#         print ('authorIDMask',authorIDMask)\n",
    "#         query_count = 10#SCOPUS_PAGE_SIZE\n",
    " \n",
    "\n",
    "# #        query = 'query=title-abs-key(a*)%20AND%20AU-ID(' + authorIDMask + ')%20AND%20(srctype(p)%20OR%20srctype(k))%20AND%20(doctype(cp))'\n",
    "#         query = 'query=title('+titleMask+')%20AND%20(srctype(p)%20OR%20srctype(k))%20AND%20(doctype(cp))'\n",
    "\n",
    "#         filter = '&count=' + str(query_count)#+ '&start=' + str(start)\n",
    "#         api_url = api_url_base + '?' + query + filter + '&apiKey=' + api_key + '&httpAccept=application%2Fjson'\n",
    "#         print (api_url)\n",
    "#         response = requests.get(api_url, headers=headers)\n",
    "#         jresponse=[]\n",
    "        \n",
    "#         if response.status_code == 200:\n",
    "#             r = json.loads(response.content.decode('utf-8'))['search-results']\n",
    "#             if 'entry' in r:\n",
    "#                 jresponse = r['entry']\n",
    "#                 if ('error' not in jresponse[0]):\n",
    "#                     results.extend(jresponse)\n",
    "#                 else:\n",
    "#                     jresponse=[]\n",
    "#         else: \n",
    "#             print('\\n \\n ******', response.status_code, response.headers, response.text)\n",
    "                    \n",
    "#         print('mask level', maskLevel, 'jresponse:', len(jresponse), \n",
    "#               'results: ', len(results), 'attempt:', attempts_with_this_mask_level,\n",
    "#               'must increase:', attempts_with_this_mask_level == MAX_ATTEMPTS_AT_MASK-1 )\n",
    "\n",
    "    \n",
    "#         if (len(jresponse)==0):\n",
    "#             if (attempts_with_this_mask_level == MAX_ATTEMPTS_AT_MASK-1):\n",
    "#                 maskLevel+=1\n",
    "#                 print('increasing maskLevel, now at ', maskLevel)\n",
    "#                 attempts_with_this_mask_level=0\n",
    "#             else:\n",
    "#                 attempts_with_this_mask_level+=1\n",
    "#         else:\n",
    "#             attempts_with_this_mask_level=0 # reset, if we get results\n",
    "#         print('(end) maskLevel now at ', maskLevel)\n",
    "\n",
    "\n",
    "#     return results\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: %%capture is a cell magic, but the cell body is empty.\n"
     ]
    }
   ],
   "source": [
    "%%capture capt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sample scopus based on title mask - by subject and year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def retrieve_randomly(retrieveCount=1000):\n",
    "#     #for i in range(10):\n",
    "#     frames=[]\n",
    "#     papers = getDOIsRandomly_titlemask(maskLevel=7, maxMaskLevel=9, retrieveCount=retrieveCount, api_key = my_api_key )\n",
    "#     df = pd.DataFrame(papers)\n",
    "#     print ('results length: ', df.shape[0])\n",
    "# #     if 'prism:doi' not in list(df.columns):\n",
    "# #         #print('no doi for '+ f)\n",
    "# #         continue\n",
    "#     to_drop = [c for c in list(df.columns) if c not in to_keep]\n",
    "#     df.drop(columns=to_drop, inplace=True)\n",
    "#     df.dropna(subset=['prism:doi'],inplace=True)\n",
    "#     df.set_index('prism:doi', inplace=True, drop=False)\n",
    "#     df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "#     df.drop_duplicates(subset='prism:doi', inplace=True)\n",
    "# #     df.drop_duplicates(subset='prism:doi', inplace=True)  \n",
    "# #     frames.append(df)\n",
    "\n",
    "\n",
    "#     return df\n",
    "\n",
    "\n",
    "def run_single_query(start,query_count,year,subjectArea,api_key,titleMask,api_url_base):\n",
    "    query = 'query=title('+titleMask+')%20AND%20(srctype(p)%20OR%20srctype(k))%20AND%20(doctype(cp))'\n",
    "    filter = '&count=' + str(query_count)+ '&start=' + str(start)+ '&date=' + str(year) + '&subj=' + subjectArea \n",
    "    api_url = api_url_base + '?' + query + filter + '&apiKey=' + api_key + '&httpAccept=application%2Fjson'\n",
    "    #print(api_url)\n",
    "    response = requests.get(api_url, headers=headers)\n",
    "    jresponse=[]\n",
    "    if response.status_code == 200:\n",
    "        r = json.loads(response.content.decode('utf-8'))['search-results']\n",
    "        if 'entry' in r:\n",
    "            jresponse = r['entry']\n",
    "            if ('error' not in jresponse[0]):\n",
    "                return jresponse\n",
    "    return []\n",
    "#             else:\n",
    "#                 return []\n",
    "#         else: \n",
    "#             print('\\n \\n ******', response.status_code, response.headers, response.text)\n",
    "                    \n",
    "        #print('jresponse:', len(jresponse), 'results: ', len(results))\n",
    "    \n",
    "\n",
    "\n",
    "def getDOIsRandomly_titlemask(retrieveCount=1000,   api_key='None', to_keep=[]):\n",
    "    #start=0\n",
    "    results = []\n",
    "    query_count = 25#SCOPUS_PAGE_SIZE\n",
    "    frames=[]\n",
    "    \n",
    "    while (len(results)<retrieveCount) :   \n",
    "        #pick a random subject\n",
    "        subjectID = random.randint(0, len(possibleSubjectAreas)-1)\n",
    "        subjectArea = possibleSubjectAreas[subjectID]\n",
    "        print ('subject:', subjectArea)    \n",
    "        #pick a random year\n",
    "        year = random.randint(2000, 2019)\n",
    "        print ('year:', year)\n",
    "        #pick a random title mask\n",
    "        titleMask = get_title_mask(2,4)\n",
    "    \n",
    "    # query scopus with these parameters\n",
    "    # also: query starts from count 4970. if this has no results, then this means this title is sufficiently random\n",
    "    # not to get into sorting bias, and we then query from the start\n",
    "\n",
    "\n",
    "        probe = run_single_query(4975,query_count,year,subjectArea,api_key,titleMask,api_url_base)\n",
    "        if (len(probe)==0): # we can start from the beginning, it is an unbiased sample\n",
    "#             continue #go to next iteration\n",
    "#         else:\n",
    "            start=0\n",
    "            while (len(results)<retrieveCount) and (start<4970) :\n",
    "                single_query_results = run_single_query(start,query_count,year,subjectArea,api_key,titleMask,api_url_base)\n",
    "                if (len(single_query_results) >0):\n",
    "                    start+=SCOPUS_PAGE_SIZE\n",
    "                    results.extend(single_query_results)\n",
    "                else:\n",
    "                    break\n",
    "                \n",
    "# #        query = 'query=title-abs-key(a*)%20AND%20AU-ID(' + authorIDMask + ')%20AND%20(srctype(p)%20OR%20srctype(k))%20AND%20(doctype(cp))'\n",
    "#         query = 'query=title('+titleMask+')%20AND%20(srctype(p)%20OR%20srctype(k))%20AND%20(doctype(cp))'\n",
    "#         filter = '&count=' + str(query_count)+ '&start=' + str(start)+ '&date=' + str(year) + '&subj=' + subjectArea \n",
    "#         api_url = api_url_base + '?' + query + filter + '&apiKey=' + api_key + '&httpAccept=application%2Fjson'\n",
    "#         print (api_url)\n",
    "#         response = requests.get(api_url, headers=headers)\n",
    "#         jresponse=[]\n",
    "        \n",
    "#         if response.status_code == 200:\n",
    "#             r = json.loads(response.content.decode('utf-8'))['search-results']\n",
    "#             if 'entry' in r:\n",
    "#                 jresponse = r['entry']\n",
    "#                 if ('error' not in jresponse[0]):\n",
    "#                     results.extend(jresponse)\n",
    "#                 else:\n",
    "#                     jresponse=[]\n",
    "#         else: \n",
    "#             print('\\n \\n ******', response.status_code, response.headers, response.text)\n",
    "                    \n",
    "            print('results: ', len(results))\n",
    "\n",
    "#         if (len(jresponse) >0):\n",
    "#             start+=SCOPUS_PAGE_SIZE\n",
    "#         else:\n",
    "#             break\n",
    "\n",
    "            df = pd.DataFrame(results)\n",
    "            df['subj'] = subjectArea\n",
    "            df['year'] = year\n",
    "            if 'prism:doi'  in list(df.columns):\n",
    "                #print('no doi for '+ f)\n",
    "                df.dropna(subset=['prism:doi'],inplace=True)\n",
    "                df.set_index('prism:doi', inplace=True, drop=False)\n",
    "                df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "                frames.append(df)\n",
    "                to_drop = [c for c in list(df.columns) if c not in to_keep]\n",
    "                df.drop(columns=to_drop, inplace=True)\n",
    "    df = pd.concat(frames)\n",
    "    df.drop_duplicates(subset='prism:doi', inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# def retrieve_randomly(retrieveCount=1000):\n",
    "#     #for i in range(10):\n",
    "# #     frames=[]\n",
    "# #     for i in range (10):\n",
    "#     df = getDOIsRandomly_titlemask(retrieveCount=retrieveCount, api_key = my_api_key )\n",
    "# #         print ('results length: ', df.shape[0])\n",
    "# #         if 'prism:doi' not in list(df.columns):\n",
    "# #             #print('no doi for '+ f)\n",
    "# #             continue\n",
    "# #         df.dropna(subset=['prism:doi'],inplace=True)\n",
    "# #         df.set_index('prism:doi', inplace=True, drop=False)\n",
    "# #         df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "# #         frames.append(df)\n",
    "        \n",
    "# #     df=pd.concat(frames)\n",
    "#     df.drop_duplicates(subset='prism:doi', inplace=True)\n",
    "\n",
    "\n",
    "#     return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def retrieve_by_subject_and_year(years, subjects, retrieveCount,folderName):\n",
    "#     for y in [2011,2012]:\n",
    "#         frames=[]\n",
    "#         for s in possibleSubjectAreas:\n",
    "#             papers = getDOIsRandomly(year=y, subjectArea=s,  maskLevel=6, \n",
    "#                 retrieveCount=RETRIEVE_COUNT, sleepInterval=10, api_key = my_api_key )\n",
    "\n",
    "#             df = pd.DataFrame(papers)\n",
    "#             print ('results length: ',s, df.shape[0])\n",
    "\n",
    "\n",
    "#             if 'prism:doi' not in list(df.columns):\n",
    "#                 #print('no doi for '+ f)\n",
    "#                 continue\n",
    "#             to_drop = [c for c in list(df.columns) if c not in to_keep]\n",
    "#             df.drop(columns=to_drop, inplace=True)\n",
    "#             df['subj'] = s\n",
    "#             df['year'] = y\n",
    "#             df.dropna(subset=['prism:doi'],inplace=True)\n",
    "#             df.set_index('prism:doi', inplace=True, drop=False)\n",
    "#             df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "#             df.drop_duplicates(subset='prism:doi', inplace=True)\n",
    "#             frames.append(df)\n",
    "\n",
    "\n",
    "#         df=pd.concat(frames)\n",
    "#         df.drop_duplicates(subset='prism:doi', inplace=True)\n",
    "#         papers_filename = folderName+'/'+str(y)+'-paper_results.csv'\n",
    "#         df.to_csv(papers_filename)\n",
    "#         #return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#https://api.elsevier.com/content/search/scopus?start=0&date=2015&count=25&subj=ECON&query=title(o*)+AND+srctype(p)&apiKey=7f59af901d2d86f78a1fd60c1bf9426a&httpAccept=application%2Fjson\n",
    "\n",
    "# results = []\n",
    "\n",
    "\n",
    "# to_keep=['prism:doi','citedby-count','openaccess','affiliation',\n",
    "#  'openaccessFlag','prism:coverDate','dc:title',\n",
    "#  'prism:coverDisplayDate', 'prism:pageRange',\n",
    "#  'prism:publicationName','subtype','subj', 'year', 'country']\n",
    "\n",
    "# RETRIEVE_COUNT=5000\n",
    "\n",
    "# dfbsy =retrieve_by_subject_and_year([2011,2012], possibleSubjectAreas, RETRIEVE_COUNT, 'randomdata')    \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1542800126\n",
      "subject: DENT\n",
      "year: 2006\n",
      "results:  0\n",
      "subject: MATE\n",
      "year: 2013\n",
      "results:  25\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "drop() got an unexpected keyword argument 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-2c02fe4acc03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m#     df=pd.concat(frames)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetDOIsRandomly_titlemask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRETRIEVE_COUNT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmy_api_key\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mto_keep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mto_keep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'citedby-count'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'citedby-count'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mpapers_filename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'data/scopus_data/title_mask/rand-paper_results'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-0a0303c600dd>\u001b[0m in \u001b[0;36mgetDOIsRandomly_titlemask\u001b[1;34m(retrieveCount, api_key, to_keep)\u001b[0m\n\u001b[0;32m    115\u001b[0m                 \u001b[0mframes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[0mto_drop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mto_keep\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m                 \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mto_drop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'prism:doi'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: drop() got an unexpected keyword argument 'columns'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "ts = time.time()\n",
    "print(int(ts))\n",
    "\n",
    "results = []\n",
    "\n",
    "\n",
    "to_keep=['prism:doi','citedby-count','openaccess','affiliation',\n",
    " 'openaccessFlag','prism:coverDate','dc:title',\n",
    " 'prism:coverDisplayDate', 'prism:pageRange',\n",
    " 'prism:publicationName','subtype','subj', 'year', 'country']\n",
    "\n",
    "RETRIEVE_COUNT=100\n",
    "\n",
    "\n",
    "    #     df=pd.concat(frames)\n",
    "df = getDOIsRandomly_titlemask(RETRIEVE_COUNT,api_key=my_api_key,to_keep=to_keep)\n",
    "df['citedby-count']=pd.to_numeric(df['citedby-count'])\n",
    "papers_filename = 'data/scopus_data/title_mask/rand-paper_results'+str(int(time.time()))+'.csv'\n",
    "df.to_csv(papers_filename)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['prism:doi'].is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['citedby-count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df['citedby-count']=pd.to_numeric(df['citedby-count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ddf['citedby-count'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# def load_clean_and_merge(folder):\n",
    "#     files = os.listdir(folder+'/')\n",
    "#     files = [f for f in files if 'csv' in f]\n",
    "#     frames=[]\n",
    "#     for f in files:\n",
    "#         df = pd.read_csv(folder+'/'+f)\n",
    "#         df['citedby-count']=pd.to_numeric(df['citedby-count'])\n",
    "#         print(df.shape)\n",
    "#         frames.append(df) \n",
    "        \n",
    "#     df = pd.concat(frames)\n",
    "#     return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cdf = load_clean_and_merge('randomdata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cdf.shape\n",
    "# cdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cdf['citedby-count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cdf.groupby(['year', 'subj'])['citedby-count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cdf.groupby('subj').size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
